This PoC reproduces, within **GitHub Actions**, the same execution flow described in the original report using only **PyGlove’s public API**. The workflow is executed manually (`workflow_dispatch`) and provisions a controlled environment (Ubuntu + Python 3.11), installs dependencies, and then runs a sequence of scripts that simulate a realistic production pipeline consuming JSON inputs from different sources.

First, `producer.py` generates a **benign control JSON** (`artifacts/benign.json`). Next, `payload_generator.py` generates a valid opaque JSON (`artifacts/poc.json`) by calling `pyglove.to_json()` on an object that cannot be represented as pure JSON, which forces PyGlove to internally use `_OpaqueObject` (pickle + base64) exactly as it does in real usage; additionally `payload_generator.py` using an external input (`oob_url`) passed the OOB from the workflow. Finally, `poc_json_conversion.py` sequentially consumes all JSON files present in `artifacts/` using `json_conversion.from_json()`, demonstrating that both benign and opaque inputs traverse the same deserialization path (`_OpaqueObject.decode` → `pickle.loads`) inside the CI pipeline, faithfully reproducing the behavior reported in a realistic and automated scenario (RCE).